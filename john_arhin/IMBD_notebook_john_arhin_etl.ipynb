{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef7c3f0-20a0-4203-95d5-6dc47c141448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Object Orientated Programming (OOP) Example Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2812ff84-cbe2-4044-b28e-210165b0f5d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Remarks\n",
    "\n",
    "We use the notebook in the project folder i.e. file IMDB_notebook.ipynb as the basis for this notebook.\n",
    "\n",
    "I want to thank [Stephen Nwoye](https://github.com/Stephen-Data-Engineer-Public) for the helpful starter code together with recommending the following helpful videos:\n",
    "\n",
    "* [Python Tutorial - Introduction to Classes](https://www.youtube.com/watch?v=u4Ryk0YuW6A) by [Dave Ebbekaar](https://www.youtube.com/@daveebbelaar), and \n",
    "* [Python OOP Tutorial 1: Classes and Instances](https://www.youtube.com/watch?v=ZDa-Z5JzLYM) by [Corey Schafer](https://www.youtube.com/@coreyms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65ddc48f-5e01-4595-bcd2-39b9eace8736",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classes\n",
    "\n",
    "We define the `DataExtractor` class to have an `extract` method, such that this method returns data in the form of a dictionary.\n",
    "\n",
    "Next, we define the `DataTransformer` class to have two methods: `checks` and `clean`. Here the `checks` method only gives print statements while the `clean` method returns data in the form of a dictionary.\n",
    "\n",
    "We define the `Dataloader` class to have a `load` method. This method just takes a parameter in the form of a path together with data as a dictionary and converts the data to multiple csv files and puts them  the given folder.\n",
    "\n",
    "Finally, we define the `ETLPipeline` class to have a single `run` method that runs the different instances of `DataExtractor`,  `DataTransformer` and `Dataloader` in sequence, such that after each main stage we load the data to files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ba3e6a-58cd-42ae-ad34-f10cf9c6f24f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class DataExtractor:\n",
    "\n",
    "    # extractor constructor\n",
    "    def __init__(self, tables: dict):\n",
    "        self.tables = tables\n",
    "\n",
    "    # extractor extract method\n",
    "    def extract(self):\n",
    "        data = {}\n",
    "        for url, table_name in self.tables.items():\n",
    "            if url.endswith('.csv'):\n",
    "                data[table_name] = pd.read_csv(url, engine=\"python\")\n",
    "            elif url.endswith('.tsv'):\n",
    "                data[table_name] = pd.read_csv(url, delimiter='\\t', engine=\"python\")\n",
    "        return data\n",
    "\n",
    "\n",
    "class DataTransformer:\n",
    "\n",
    "    # transformer constructor\n",
    "    def __init__(self, columns_to_clean: dict, needed_table: list):\n",
    "        self.columns_to_clean = columns_to_clean\n",
    "        self.needed_table = needed_table\n",
    "\n",
    "    # transformer method that combines checks\n",
    "    def checks(self, data):\n",
    "\n",
    "        # loop through data wanting tables\n",
    "        for table, _ in data.items():\n",
    "\n",
    "            # conditional statement using needed_table\n",
    "            if table in self.needed_table:\n",
    "                print(table)\n",
    "\n",
    "                # null check\n",
    "                null_count = data[table].isna().sum()\n",
    "                print(null_count)\n",
    "\n",
    "                # table info check\n",
    "                print((data[table]).info())\n",
    "                print(\"---\")\n",
    "\n",
    "    # transformer clean method\n",
    "    def clean(self, data):\n",
    "\n",
    "        # loop through items in dictionary\n",
    "        for table_name, columns in self.columns_to_clean.items():\n",
    "\n",
    "            # we remove NA and fill NA with zeros on tables\n",
    "            if table_name == \"Domestic_Box_Office_Franchises\":\n",
    "                data[table_name] = data[table_name].fillna(0)\n",
    "            else:\n",
    "                data[table_name] = data[table_name].dropna()\n",
    "\n",
    "            # inner loop\n",
    "            # remove dollar signs and commas\n",
    "            # convert column to numeric type\n",
    "            for col in columns:\n",
    "                if data[table_name][col].dtype == 'object':\n",
    "                    data[table_name][col] = (\n",
    "                        data[table_name][col]\n",
    "                        .str.replace('$', '', regex=False)\n",
    "                        .str.replace(',', '', regex=False)\n",
    "                    )\n",
    "                    data[table_name][col] = pd.to_numeric(data[table_name][col], errors='coerce')\n",
    "        return data\n",
    "    \n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    # loader constructor\n",
    "    def __init__(self, destination_folder: str):\n",
    "        self.destination_folder = destination_folder\n",
    "\n",
    "    # loader load method\n",
    "    def load(self, data):\n",
    "        os.makedirs(self.destination_folder, exist_ok=True)\n",
    "        for table_name, df in data.items():\n",
    "            path = os.path.join(self.destination_folder, f\"{table_name}.csv\")\n",
    "            df.to_csv(path, index=False)\n",
    "\n",
    "# \n",
    "class ETLPipeline:\n",
    "\n",
    "    # ETL pipeline constructor\n",
    "    def __init__(self, tables, columns_to_clean, folders, needed_table):\n",
    "        self.extractor = DataExtractor(tables)\n",
    "        self.transformer = DataTransformer(columns_to_clean, needed_table)\n",
    "        self.raw_folder, self.clean_folder, self.transformed_folder = folders\n",
    "\n",
    "    # etl pipeline run method\n",
    "    def run(self):\n",
    "        print(\"Extracting data...\")\n",
    "        data = self.extractor.extract()\n",
    "\n",
    "        print(\"Saving raw data...\")\n",
    "        DataLoader(self.raw_folder).load(data)\n",
    "\n",
    "        print(\"Checking Data\")\n",
    "        self.transformer.checks(data)\n",
    "\n",
    "        print(\"Cleaning data...\")\n",
    "        cleaned = self.transformer.clean(data)\n",
    "        DataLoader(self.clean_folder).load(cleaned)\n",
    "\n",
    "        print(\"Transforming data...\")\n",
    "        # your transform_data() logic can go here\n",
    "        transformed = cleaned  # placeholder\n",
    "        DataLoader(self.transformed_folder).load(transformed)\n",
    "\n",
    "        print(\"ETL complete!\")\n",
    "\n",
    "# we use this line in order to make the commands run in a certain way\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    TABLES = {\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/MovieLens_movies.csv\": \"movies_Id\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/IMDb%20BoxOfficeMojo%20-%20Brands%20(US%20%26%20Canada).tsv\": \"brands_US_and_Canada\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/IMDb%20BoxOfficeMojo%20-%20Brand_%20Marvel%20Comics.tsv\": \"brand_marvel_comics\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/The%20Numbers%20-%20Domestic%20Box%20Office%20Daily%20-%20The%20Avengers.tsv\": \"Domestic_Box_Office_Daily_The_Avengers\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/The%20Numbers%20-%20Domestic%20Box%20Office%20-%20Franchises.tsv\": \"Domestic_Box_Office_Franchises\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/The%20Numbers%20-%20Domestic%20Box%20Office%20-%20Franchises%20-%20Marvel%20Cinematic%20Universe.tsv\": \"Domestic_Box_Office_Franchises_Marvel_Cinematic\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/World%20Wide%20Box%20Office%20All%20Time%20Top%201000.tsv\": \"World_Wide_Box_Office_All_Time_Top_1000\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/IMDb%20BoxOfficeMojo%20-%20Franchises%20(US%20%26%20Canada).tsv\": \"Franchises_us_and_Canada\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/IMDb%20BoxOfficeMojo%20-%20Franchise_%20top20.tsv\": \"top_20_for_each_Franchise\",\n",
    "    \"https://raw.githubusercontent.com/mansik95/IMDB-Analysis/master/Data/MovieLens_tags.csv\": \"tags\"\n",
    "    }\n",
    "\n",
    "    COLUMNS_TO_CLEAN = {\n",
    "        'Domestic_Box_Office_Franchises': ['Domestic_Box_Office', 'Infl_Adj_Dom_Box_Office', 'Worldwide_Box_Office'],\n",
    "        'Domestic_Box_Office_Franchises_Marvel_Cinematic': ['Production_Budget', 'Opening_Weekend', 'Domestic_Box_Office', 'Worldwide_Box_Office'],\n",
    "        'top_20_for_each_Franchise': ['Lifetime_Gross','Opening_Gross','Max_Theaters']\n",
    "    }\n",
    "\n",
    "    FOLDERS = (\n",
    "        \"/Workspace/Users/john.arhin@gmail.com/Full-Stack-IMBD-Data-Analysis/src/RAW_DATA_FOLDER\",\n",
    "        \"/Workspace/Users/john.arhin@gmail.com/Full-Stack-IMBD-Data-Analysis/src/CLEANED_DATA_FOLDER\",\n",
    "        \"/Workspace/Users/john.arhin@gmail.com/Full-Stack-IMBD-Data-Analysis/src/TRANSFORMED_DATA_FOLDER\"\n",
    "    )\n",
    "\n",
    "\n",
    "    NEEDED_TABLE = [\"tags\",\"Domestic_Box_Office_Franchises_Marvel_Cinematic\",\"movies_Id\",\"brands_US_and_Canada\",\"Domestic_Box_Office_Franchises\",\"World_Wide_Box_Office_All_Time_Top_1000\",\"top_20_for_each_Franchise\"]\n",
    "\n",
    "    pipeline = ETLPipeline(TABLES, COLUMNS_TO_CLEAN, FOLDERS, NEEDED_TABLE)\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa1b35a2-7e7a-4cb1-ae78-08f432fb58dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We remark that the use of the conditional variable check `if __name__ == \"__main__\"` is explained in this video [Python Tutorial: if __name__ == '__main__'](https://www.youtube.com/watch?v=sugvnHA7ElY)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Databricks run of this notebook can be found [here](https://dbc-54b899f0-8dbe.cloud.databricks.com/jobs/3957824083901/runs/950822748280727?o=2413881793511514)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "IMBD_notebook_john_arhin_etl",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
